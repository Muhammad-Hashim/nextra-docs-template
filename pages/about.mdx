## Welcome to Tiny Corp, Creators of Tinygrad

At Tiny Corp, we take pride in being the architects and maintainers of tinygrad, a rapidly advancing neural network framework boasting over 9000 GitHub stars. We are committed to simplicity, and tinygrad achieves this by distilling the complexities of neural networks into four fundamental OpTypes.

### Key OpTypes in Tinygrad

1. **UnaryOps:**
   - Operate on a single tensor, executing elementwise operations such as RELU, LOG, RECIPROCAL, and more.
2. **BinaryOps:**
   - Perform elementwise operations on two tensors, yielding a single output. Common operations include ADD, MUL, and others.
3. **ReduceOps:**
   - Operate on a single tensor to produce a smaller tensor. Examples include SUM, MAX, and other reduction operations.
4. **MovementOps:**
   - Manipulate data within a tensor, ensuring copy-free operations with ShapeTracker. Operations like RESHAPE, PERMUTE, EXPAND, and more fall under this category.
"But where are the CONVs and MATMULs?" you may wonder. Delve into the intricacies of our codebase to unravel this mystery. Tinygrad's design principles prioritize transparency and efficiency, inviting you to explore and comprehend the magic behind these seemingly absent operations.

### Unraveling the Code

To fully grasp the absence of CONVs and MATMULs, we encourage you to dive into our meticulously crafted codebase. Tinygrad's elegance lies in its simplicity, and we invite you to explore the source to discover how we achieve high performance while maintaining clarity.

Thank you for choosing tinygrad. Join us on this journey of exploration, innovation, and efficient neural network frameworks.

Best regards,
The Tiny Corp Team
